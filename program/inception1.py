# -*- coding: utf-8 -*-
"""Inception1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16outhPAqYipFAIxFYWKPUPtZTbrif2zM
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.inception_v3 import InceptionV3
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Set the data directory and image dimensions
data_dir = r'/content/drive/MyDrive/AI-Intern Project/Tea leaf Disease Detection/tea sickness dataset'
img_height, img_width = 224, 224
batch_size = 32

# Set up data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)

# Load and preprocess the training dataset
train_data = train_datagen.flow_from_directory(
    data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training')

# Load and preprocess the validation dataset
val_data = train_datagen.flow_from_directory(
    data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation')

# Load the InceptionV3 base model without the top layers
base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))

# Freeze the layers of the base model
for layer in base_model.layers:
    layer.trainable = False

# Add custom classification layers on top of the base model
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation='relu')(x)
predictions = Dense(train_data.num_classes, activation='softmax')(x)

# Create the model with InceptionV3 as the base and custom classification layers
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_data, epochs=25, validation_data=val_data)

# Evaluate the model on the validation dataset
val_loss, val_accuracy = model.evaluate(val_data)
print(f'Validation Loss: {val_loss:.4f}')
print(f'Validation Accuracy: {val_accuracy:.4f}')

# Plot loss and accuracy
def plot_metrics(history):
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.show()

plot_metrics(history)

# Load and preprocess the test dataset
test_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.6)
test_data = test_datagen.flow_from_directory(
    data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation')

# Evaluate the model on the test dataset
test_loss, test_accuracy = model.evaluate(test_data)
print(f'Test Loss: {test_loss:.4f}')
print(f'Test Accuracy: {test_accuracy:.4f}')

# Get true and predicted labels for the test dataset
true_labels = test_data.classes
predicted_labels = model.predict(test_data)
predicted_labels = np.argmax(predicted_labels, axis=1)

# Generate and print classification report
print(classification_report(true_labels, predicted_labels, target_names=list(test_data.class_indices.keys())))

# Plot sample predictions with confidence percentages
def plot_sample_predictions(test_data, model, num_images=5):
    test_images, test_labels = next(test_data)
    predictions = model.predict(test_images)
    predicted_labels = np.argmax(predictions, axis=1)
    class_names = list(test_data.class_indices.keys())
    true_labels = np.argmax(test_labels, axis=1)

    fig, axes = plt.subplots(1, num_images, figsize=(20, 5))
    for i, ax in enumerate(axes):
        ax.imshow(test_images[i])
        ax.axis('off')
        predicted_class = class_names[predicted_labels[i]]
        true_class = class_names[true_labels[i]]
        confidence = np.max(predictions[i]) * 100
        ax.set_title(f"Predicted: {predicted_class} ({confidence:.2f}%)\nTrue: {true_class}")

    plt.show()

plot_sample_predictions(test_data, model)

model.save("/content/drive/MyDrive/AI-Intern Project/Tea leaf Disease Detection/saved models/Inception1.h5")